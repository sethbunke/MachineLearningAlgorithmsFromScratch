{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.001, error=46.236\n",
      ">epoch=1, lrate=0.001, error=41.305\n",
      ">epoch=2, lrate=0.001, error=36.930\n",
      ">epoch=3, lrate=0.001, error=33.047\n",
      ">epoch=4, lrate=0.001, error=29.601\n",
      ">epoch=5, lrate=0.001, error=26.543\n",
      ">epoch=6, lrate=0.001, error=23.830\n",
      ">epoch=7, lrate=0.001, error=21.422\n",
      ">epoch=8, lrate=0.001, error=19.285\n",
      ">epoch=9, lrate=0.001, error=17.389\n",
      ">epoch=10, lrate=0.001, error=15.706\n",
      ">epoch=11, lrate=0.001, error=14.213\n",
      ">epoch=12, lrate=0.001, error=12.888\n",
      ">epoch=13, lrate=0.001, error=11.712\n",
      ">epoch=14, lrate=0.001, error=10.668\n",
      ">epoch=15, lrate=0.001, error=9.742\n",
      ">epoch=16, lrate=0.001, error=8.921\n",
      ">epoch=17, lrate=0.001, error=8.191\n",
      ">epoch=18, lrate=0.001, error=7.544\n",
      ">epoch=19, lrate=0.001, error=6.970\n",
      ">epoch=20, lrate=0.001, error=6.461\n",
      ">epoch=21, lrate=0.001, error=6.009\n",
      ">epoch=22, lrate=0.001, error=5.607\n",
      ">epoch=23, lrate=0.001, error=5.251\n",
      ">epoch=24, lrate=0.001, error=4.935\n",
      ">epoch=25, lrate=0.001, error=4.655\n",
      ">epoch=26, lrate=0.001, error=4.406\n",
      ">epoch=27, lrate=0.001, error=4.186\n",
      ">epoch=28, lrate=0.001, error=3.990\n",
      ">epoch=29, lrate=0.001, error=3.816\n",
      ">epoch=30, lrate=0.001, error=3.662\n",
      ">epoch=31, lrate=0.001, error=3.525\n",
      ">epoch=32, lrate=0.001, error=3.404\n",
      ">epoch=33, lrate=0.001, error=3.296\n",
      ">epoch=34, lrate=0.001, error=3.200\n",
      ">epoch=35, lrate=0.001, error=3.115\n",
      ">epoch=36, lrate=0.001, error=3.040\n",
      ">epoch=37, lrate=0.001, error=2.973\n",
      ">epoch=38, lrate=0.001, error=2.914\n",
      ">epoch=39, lrate=0.001, error=2.862\n",
      ">epoch=40, lrate=0.001, error=2.815\n",
      ">epoch=41, lrate=0.001, error=2.773\n",
      ">epoch=42, lrate=0.001, error=2.737\n",
      ">epoch=43, lrate=0.001, error=2.704\n",
      ">epoch=44, lrate=0.001, error=2.675\n",
      ">epoch=45, lrate=0.001, error=2.650\n",
      ">epoch=46, lrate=0.001, error=2.627\n",
      ">epoch=47, lrate=0.001, error=2.607\n",
      ">epoch=48, lrate=0.001, error=2.589\n",
      ">epoch=49, lrate=0.001, error=2.573\n",
      "[0.22998234937311363, 0.8017220304137576]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "def predict(row, coefficients):\n",
    "\tyhat = coefficients[0]\n",
    "\tfor i in range(len(row)-1):\n",
    "\t\tyhat += coefficients[i + 1] * row[i]\n",
    "\treturn yhat\n",
    "\n",
    "# Estimate linear regression coefficients using stochastic gradient descent\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "\tcoef = [0.0 for i in range(len(train[0]))]\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tsum_error = 0\n",
    "\t\tfor row in train:\n",
    "\t\t\tyhat = predict(row, coef)\n",
    "\t\t\terror = yhat - row[-1]\n",
    "\t\t\tsum_error += error**2\n",
    "\t\t\tcoef[0] = coef[0] - l_rate * error\n",
    "\t\t\tfor i in range(len(row)-1):\n",
    "\t\t\t\tcoef[i + 1] = coef[i + 1] - l_rate * error * row[i]\n",
    "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "\treturn coef\n",
    "\n",
    "# Calculate coefficients\n",
    "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
    "l_rate = 0.001\n",
    "n_epoch = 50\n",
    "coef = coefficients_sgd(dataset, l_rate, n_epoch)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1]\n",
      "Expected=1.000, Predicted=1.200\n",
      "[2, 3]\n",
      "Expected=3.000, Predicted=2.000\n",
      "[4, 3]\n",
      "Expected=3.000, Predicted=3.600\n",
      "[3, 2]\n",
      "Expected=2.000, Predicted=2.800\n",
      "[5, 5]\n",
      "Expected=5.000, Predicted=4.400\n"
     ]
    }
   ],
   "source": [
    "# Example of making a prediction with coefficients\n",
    "\n",
    "# Make a prediction\n",
    "def predict(row, coefficients):\n",
    "    print(row)\n",
    "    yhat = coefficients[0]\n",
    "    for i in range(len(row)-1):\n",
    "#         print(i)\n",
    "#         print(row[i])\n",
    "#         print(coefficients[i + 1])\n",
    "        yhat += coefficients[i + 1] * row[i] #x value from row and second coefficient\n",
    "    return yhat\n",
    "\n",
    "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
    "coef = [0.4, 0.8]\n",
    "for row in dataset:\n",
    "    yhat = predict(row, coef)\n",
    "    print(\"Expected=%.3f, Predicted=%.3f\" % (row[-1], yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultivariateLinearRegression:   \n",
    "    def train(self, train, learning_rate, epochs):      \n",
    "        self.train = train\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.train_column_count = len(train[0])\n",
    "        self.__coefficients = self.coefficients_sgd()\n",
    "        \n",
    "    def get_coefficients(self):\n",
    "        return self.__coefficients\n",
    "    \n",
    "    def __predict_row(self, row, coefficients):\n",
    "        #coefficients[0] is the b in y = mx + b; the bias that \n",
    "        #will be the intial value of the coefficient\n",
    "        predicted_value = coefficients[0]        \n",
    "        row_length_minus_1 = self.train_column_count - 1\n",
    "        \n",
    "        #for each item in the row (except that last column which should be the actual value), \n",
    "        #apply the appropriate coefficient to the value and add to predicted value\n",
    "        for i in range(row_length_minus_1):\n",
    "            predicted_value += coefficients[i + 1] * row[i]\n",
    "        return predicted_value\n",
    "    \n",
    "    def coefficients_sgd(self):\n",
    "        #start with zeroes for coefficients\n",
    "        coefficients = [0.0 for i in range(self.train_column_count)]         \n",
    "        for epoch in range(self.epochs):            \n",
    "            sum_error = 0\n",
    "            for row in self.train:\n",
    "                #get predicted value for each row\n",
    "                predicted_row_value = self.__predict_row(row, coefficients)                 \n",
    "                #calculate error, which is the predicted value minus actual value\n",
    "                error = predicted_row_value - row[-1]\n",
    "                #square the error and add it to the total error for the epoch\n",
    "                sum_error += error**2\n",
    "                #upate the y-intercept coefficient (bias) based on the error and learning rate\n",
    "                coefficients[0] = coefficients[0] - (self.learning_rate * error) \n",
    "                #update the other coefficients based on the error and the learning rate\n",
    "                for i in range(len(row)-1):\n",
    "                    coefficients[i + 1] = coefficients[i + 1] - self.learning_rate * error * row[i]\n",
    "                #print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, self.learning_rate, sum_error))\n",
    "        return coefficients\n",
    "    \n",
    "    def predict(self, data):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22998234937311363, 0.8017220304137576]\n"
     ]
    }
   ],
   "source": [
    "# Calculate coefficients\n",
    "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
    "l_rate = 0.001\n",
    "n_epoch = 50\n",
    "#coef = coefficients_sgd(dataset, l_rate, n_epoch)\n",
    "#print(coef)\n",
    "\n",
    "t = MultivariateLinearRegression()\n",
    "t.train(dataset, l_rate, n_epoch)\n",
    "print(t.get_coefficients())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhat> 0.4\n",
      "coef: 0.8\n",
      "1.2000000000000002 = 0.4 + (0.8 * 1)\n",
      "RESULT: yhat: 1.2000000000000002 coef: 0.8 row val: 1\n",
      "Expected=1.000, Predicted=1.200\n",
      "yhat> 0.4\n",
      "coef: 0.8\n",
      "2.0 = 0.4 + (0.8 * 2)\n",
      "RESULT: yhat: 2.0 coef: 0.8 row val: 2\n",
      "Expected=3.000, Predicted=2.000\n",
      "yhat> 0.4\n",
      "coef: 0.8\n",
      "3.6 = 0.4 + (0.8 * 4)\n",
      "RESULT: yhat: 3.6 coef: 0.8 row val: 4\n",
      "Expected=3.000, Predicted=3.600\n",
      "yhat> 0.4\n",
      "coef: 0.8\n",
      "2.8000000000000003 = 0.4 + (0.8 * 3)\n",
      "RESULT: yhat: 2.8000000000000003 coef: 0.8 row val: 3\n",
      "Expected=2.000, Predicted=2.800\n",
      "yhat> 0.4\n",
      "coef: 0.8\n",
      "4.4 = 0.4 + (0.8 * 5)\n",
      "RESULT: yhat: 4.4 coef: 0.8 row val: 5\n",
      "Expected=5.000, Predicted=4.400\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "def predict(row, coefficients):\n",
    "    yhat = coefficients[0] #this is the y-intercept\n",
    "    print(\"yhat> \" + str(yhat))\n",
    "    for i in range(len(row)-1): #from 0 to the number of items in row - 1\n",
    "        c = coefficients[i + 1]\n",
    "        r = row[i] \n",
    "        y = yhat\n",
    "        print('coef: ' + str(c))\n",
    "        yhat += coefficients[i + 1] * row[i]\n",
    "        \n",
    "        print(str(yhat) + \" = \" + str(y) + \" + (\" + str(c) + \" * \" + str(r) + \")\")\n",
    "        print(\"RESULT: yhat: \" + str(yhat) + \" coef: \" + str(c) + \" row val: \" + str(r))\n",
    "    return yhat #return total for all rows\n",
    "\n",
    "\n",
    "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
    "coef = [0.4, 0.8]\n",
    "for row in dataset:\n",
    "  yhat = predict(row, coef)\n",
    "  print(\"Expected=%.3f, Predicted=%.3f\" % (row[-1], yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "yhat> 0.0\n",
      "0\n",
      ">epoch=0, lrate=0.001, error=1.000\n",
      "yhat> 0.001\n",
      "0\n",
      ">epoch=0, lrate=0.001, error=9.982\n",
      "yhat> 0.0039970000000000006\n",
      "0\n",
      ">epoch=0, lrate=0.001, error=18.791\n",
      "yhat> 0.006965027\n",
      "0\n",
      ">epoch=0, lrate=0.001, error=22.541\n",
      "yhat> 0.008901463649000001\n",
      "0\n",
      ">epoch=0, lrate=0.001, error=46.236\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "yhat> 0.013769185095616001\n",
      "0\n",
      ">epoch=1, lrate=0.001, error=0.878\n",
      "yhat> 0.014706401885340305\n",
      "0\n",
      ">epoch=1, lrate=0.001, error=9.204\n",
      "yhat> 0.017591792999515358\n",
      "0\n",
      ">epoch=1, lrate=0.001, error=16.819\n",
      "yhat> 0.020351313109723226\n",
      "0\n",
      ">epoch=1, lrate=0.001, error=19.985\n",
      "yhat> 0.022130681482696545\n",
      "0\n",
      ">epoch=1, lrate=0.001, error=41.305\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "yhat> 0.026748059752424322\n",
      "0\n",
      ">epoch=2, lrate=0.001, error=0.771\n",
      "yhat> 0.027626126591565353\n",
      "0\n",
      ">epoch=2, lrate=0.001, error=8.501\n",
      "yhat> 0.030406374129082415\n",
      "0\n",
      ">epoch=2, lrate=0.001, error=15.070\n",
      "yhat> 0.032969473102870454\n",
      "0\n",
      ">epoch=2, lrate=0.001, error=17.732\n",
      "yhat> 0.034600875453019965\n",
      "0\n",
      ">epoch=2, lrate=0.001, error=36.930\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "yhat> 0.03898242324773534\n",
      "0\n",
      ">epoch=3, lrate=0.001, error=0.676\n",
      "yhat> 0.03980476281954771\n",
      "0\n",
      ">epoch=3, lrate=0.001, error=7.865\n",
      "yhat> 0.04248595736770474\n",
      "0\n",
      ">epoch=3, lrate=0.001, error=13.520\n",
      "yhat> 0.04486402047590494\n",
      "0\n",
      ">epoch=3, lrate=0.001, error=15.746\n",
      "yhat> 0.046356031497306556\n",
      "0\n",
      ">epoch=3, lrate=0.001, error=33.047\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "yhat> 0.0505154203702841\n",
      "0\n",
      ">epoch=4, lrate=0.001, error=0.593\n",
      "yhat> 0.0512852569864439\n",
      "0\n",
      ">epoch=4, lrate=0.001, error=7.290\n",
      "yhat> 0.0538731361292853\n",
      "0\n",
      ">epoch=4, lrate=0.001, error=12.146\n",
      "yhat> 0.05607688875966897\n",
      "0\n",
      ">epoch=4, lrate=0.001, error=13.998\n",
      "yhat> 0.05743758616422942\n",
      "0\n",
      ">epoch=4, lrate=0.001, error=29.601\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "yhat> 0.06138769527253031\n",
      "0\n",
      ">epoch=5, lrate=0.001, error=0.519\n",
      "yhat> 0.0621080663706093\n",
      "0\n",
      ">epoch=5, lrate=0.001, error=6.769\n",
      "yhat> 0.06460803514874557\n",
      "0\n",
      ">epoch=5, lrate=0.001, error=10.929\n",
      "yhat> 0.0666475810523855\n",
      "0\n",
      ">epoch=5, lrate=0.001, error=12.459\n",
      "yhat> 0.06788457437458094\n",
      "0\n",
      ">epoch=5, lrate=0.001, error=26.543\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "yhat> 0.07163753640578646\n",
      "0\n",
      ">epoch=6, lrate=0.001, error=0.454\n",
      "yhat> 0.07231130338034067\n",
      "0\n",
      ">epoch=6, lrate=0.001, error=6.297\n",
      "yhat> 0.07472845356493121\n",
      "0\n",
      ">epoch=6, lrate=0.001, error=9.849\n",
      "yhat> 0.07661331088583131\n",
      "0\n",
      ">epoch=6, lrate=0.001, error=11.105\n",
      "yhat> 0.07773376861794346\n",
      "0\n",
      ">epoch=6, lrate=0.001, error=23.830\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "yhat> 0.08130101305500713\n",
      "0\n",
      ">epoch=7, lrate=0.001, error=0.397\n",
      "yhat> 0.08193087146090312\n",
      "0\n",
      ">epoch=7, lrate=0.001, error=5.868\n",
      "yhat> 0.08426999971053244\n",
      "0\n",
      ">epoch=7, lrate=0.001, error=8.893\n",
      "yhat> 0.0860091349270053\n",
      "0\n",
      ">epoch=7, lrate=0.001, error=9.914\n",
      "yhat> 0.08701981008161817\n",
      "0\n",
      ">epoch=7, lrate=0.001, error=21.422\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "yhat> 0.09041210396011715\n",
      "0\n",
      ">epoch=8, lrate=0.001, error=0.346\n",
      "yhat> 0.09100059312448065\n",
      "0\n",
      ">epoch=8, lrate=0.001, error=5.479\n",
      "yhat> 0.0932662180896747\n",
      "0\n",
      ">epoch=8, lrate=0.001, error=8.045\n",
      "yhat> 0.09486807798850051\n",
      "0\n",
      ">epoch=8, lrate=0.001, error=8.868\n",
      "yhat> 0.09577533217941273\n",
      "0\n",
      ">epoch=8, lrate=0.001, error=19.285\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "yhat> 0.09900281848253747\n",
      "0\n",
      ">epoch=9, lrate=0.001, error=0.302\n",
      "yhat> 0.09955233055960015\n",
      "0\n",
      ">epoch=9, lrate=0.001, error=5.126\n",
      "yhat> 0.10174870899597685\n",
      "0\n",
      ">epoch=9, lrate=0.001, error=7.294\n",
      "yhat> 0.10322125079336245\n",
      "0\n",
      ">epoch=9, lrate=0.001, error=7.950\n",
      "yhat> 0.10403107692078664\n",
      "0\n",
      ">epoch=9, lrate=0.001, error=17.389\n",
      "[0.10710331074898374, 0.3801081881174074]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "def predict(row, coefficients):\n",
    "    yhat = coefficients[0] #this is the y-intercept\n",
    "    print(\"yhat> \" + str(yhat))\n",
    "    for i in range(len(row)-1): #from 0 to the number of items in row - 1\n",
    "        print(i)\n",
    "        yhat += coefficients[i + 1] * row[i]\n",
    "    return yhat\n",
    "\n",
    "# Estimate linear regression coefficients using stochastic gradient descent\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "    coef = [0.0 for i in range(len(train[0]))] #start with zeroes for coefficients\n",
    "    #the number of coefficients is the number of features in each row    \n",
    "    print(coef)\n",
    "    for epoch in range(n_epoch):\n",
    "        print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            #for each row\n",
    "            yhat = predict(row, coef) #yhat is the predicted value\n",
    "            #print(row[-1])\n",
    "            #error = prediction - actual value\n",
    "            error = yhat - row[-1] # yhat minus last colum in row (actual value)\n",
    "            sum_error += error**2\n",
    "            #update the y-intercept coefficient based on the error and the learning rate\n",
    "            coef[0] = coef[0] - l_rate * error #y-intercept\n",
    "            #update the other coefficients based on the error and the learning rate\n",
    "            for i in range(len(row)-1):\n",
    "                coef[i + 1] = coef[i + 1] - l_rate * error * row[i]\n",
    "            print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "    return coef\n",
    "\n",
    "# Calculate coefficients\n",
    "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
    "l_rate = 0.001\n",
    "n_epoch = 10\n",
    "coef = coefficients_sgd(dataset, l_rate, n_epoch)\n",
    "print(coef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Example of estimating coefficients\n",
    "# Make a prediction\n",
    "def predict(row, coefficients):\n",
    "    yhat = coefficients[0]\n",
    "    for i in range(len(row)-1):\n",
    "        yhat += coefficients[i + 1] * row[i]\n",
    "    return yhat\n",
    "# Estimate linear regression coefficients using stochastic gradient descent\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "    coef = [0.0 for i in range(len(train[0]))]\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            yhat = predict(row, coef)\n",
    "            error = yhat - row[-1]\n",
    "            sum_error += error**2\n",
    "            coef[0] = coef[0] - l_rate * error\n",
    "            for i in range(len(row)-1):\n",
    "                coef[i + 1] = coef[i + 1] - l_rate * error * row[i] \n",
    "            print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.001, error=1.000\n",
      ">epoch=0, lrate=0.001, error=9.982\n",
      ">epoch=0, lrate=0.001, error=18.791\n",
      ">epoch=0, lrate=0.001, error=22.541\n",
      ">epoch=0, lrate=0.001, error=46.236\n",
      ">epoch=1, lrate=0.001, error=0.878\n",
      ">epoch=1, lrate=0.001, error=9.204\n",
      ">epoch=1, lrate=0.001, error=16.819\n",
      ">epoch=1, lrate=0.001, error=19.985\n",
      ">epoch=1, lrate=0.001, error=41.305\n",
      ">epoch=2, lrate=0.001, error=0.771\n",
      ">epoch=2, lrate=0.001, error=8.501\n",
      ">epoch=2, lrate=0.001, error=15.070\n",
      ">epoch=2, lrate=0.001, error=17.732\n",
      ">epoch=2, lrate=0.001, error=36.930\n",
      ">epoch=3, lrate=0.001, error=0.676\n",
      ">epoch=3, lrate=0.001, error=7.865\n",
      ">epoch=3, lrate=0.001, error=13.520\n",
      ">epoch=3, lrate=0.001, error=15.746\n",
      ">epoch=3, lrate=0.001, error=33.047\n",
      ">epoch=4, lrate=0.001, error=0.593\n",
      ">epoch=4, lrate=0.001, error=7.290\n",
      ">epoch=4, lrate=0.001, error=12.146\n",
      ">epoch=4, lrate=0.001, error=13.998\n",
      ">epoch=4, lrate=0.001, error=29.601\n",
      ">epoch=5, lrate=0.001, error=0.519\n",
      ">epoch=5, lrate=0.001, error=6.769\n",
      ">epoch=5, lrate=0.001, error=10.929\n",
      ">epoch=5, lrate=0.001, error=12.459\n",
      ">epoch=5, lrate=0.001, error=26.543\n",
      ">epoch=6, lrate=0.001, error=0.454\n",
      ">epoch=6, lrate=0.001, error=6.297\n",
      ">epoch=6, lrate=0.001, error=9.849\n",
      ">epoch=6, lrate=0.001, error=11.105\n",
      ">epoch=6, lrate=0.001, error=23.830\n",
      ">epoch=7, lrate=0.001, error=0.397\n",
      ">epoch=7, lrate=0.001, error=5.868\n",
      ">epoch=7, lrate=0.001, error=8.893\n",
      ">epoch=7, lrate=0.001, error=9.914\n",
      ">epoch=7, lrate=0.001, error=21.422\n",
      ">epoch=8, lrate=0.001, error=0.346\n",
      ">epoch=8, lrate=0.001, error=5.479\n",
      ">epoch=8, lrate=0.001, error=8.045\n",
      ">epoch=8, lrate=0.001, error=8.868\n",
      ">epoch=8, lrate=0.001, error=19.285\n",
      ">epoch=9, lrate=0.001, error=0.302\n",
      ">epoch=9, lrate=0.001, error=5.126\n",
      ">epoch=9, lrate=0.001, error=7.294\n",
      ">epoch=9, lrate=0.001, error=7.950\n",
      ">epoch=9, lrate=0.001, error=17.389\n",
      ">epoch=10, lrate=0.001, error=0.263\n",
      ">epoch=10, lrate=0.001, error=4.805\n",
      ">epoch=10, lrate=0.001, error=6.629\n",
      ">epoch=10, lrate=0.001, error=7.145\n",
      ">epoch=10, lrate=0.001, error=15.706\n",
      ">epoch=11, lrate=0.001, error=0.229\n",
      ">epoch=11, lrate=0.001, error=4.512\n",
      ">epoch=11, lrate=0.001, error=6.040\n",
      ">epoch=11, lrate=0.001, error=6.439\n",
      ">epoch=11, lrate=0.001, error=14.213\n",
      ">epoch=12, lrate=0.001, error=0.199\n",
      ">epoch=12, lrate=0.001, error=4.246\n",
      ">epoch=12, lrate=0.001, error=5.518\n",
      ">epoch=12, lrate=0.001, error=5.821\n",
      ">epoch=12, lrate=0.001, error=12.888\n",
      ">epoch=13, lrate=0.001, error=0.172\n",
      ">epoch=13, lrate=0.001, error=4.003\n",
      ">epoch=13, lrate=0.001, error=5.056\n",
      ">epoch=13, lrate=0.001, error=5.280\n",
      ">epoch=13, lrate=0.001, error=11.712\n",
      ">epoch=14, lrate=0.001, error=0.149\n",
      ">epoch=14, lrate=0.001, error=3.781\n",
      ">epoch=14, lrate=0.001, error=4.646\n",
      ">epoch=14, lrate=0.001, error=4.807\n",
      ">epoch=14, lrate=0.001, error=10.668\n",
      ">epoch=15, lrate=0.001, error=0.129\n",
      ">epoch=15, lrate=0.001, error=3.579\n",
      ">epoch=15, lrate=0.001, error=4.284\n",
      ">epoch=15, lrate=0.001, error=4.395\n",
      ">epoch=15, lrate=0.001, error=9.742\n",
      ">epoch=16, lrate=0.001, error=0.111\n",
      ">epoch=16, lrate=0.001, error=3.394\n",
      ">epoch=16, lrate=0.001, error=3.963\n",
      ">epoch=16, lrate=0.001, error=4.035\n",
      ">epoch=16, lrate=0.001, error=8.921\n",
      ">epoch=17, lrate=0.001, error=0.095\n",
      ">epoch=17, lrate=0.001, error=3.224\n",
      ">epoch=17, lrate=0.001, error=3.679\n",
      ">epoch=17, lrate=0.001, error=3.722\n",
      ">epoch=17, lrate=0.001, error=8.191\n",
      ">epoch=18, lrate=0.001, error=0.082\n",
      ">epoch=18, lrate=0.001, error=3.069\n",
      ">epoch=18, lrate=0.001, error=3.428\n",
      ">epoch=18, lrate=0.001, error=3.451\n",
      ">epoch=18, lrate=0.001, error=7.544\n",
      ">epoch=19, lrate=0.001, error=0.070\n",
      ">epoch=19, lrate=0.001, error=2.927\n",
      ">epoch=19, lrate=0.001, error=3.205\n",
      ">epoch=19, lrate=0.001, error=3.215\n",
      ">epoch=19, lrate=0.001, error=6.970\n",
      ">epoch=20, lrate=0.001, error=0.060\n",
      ">epoch=20, lrate=0.001, error=2.796\n",
      ">epoch=20, lrate=0.001, error=3.008\n",
      ">epoch=20, lrate=0.001, error=3.011\n",
      ">epoch=20, lrate=0.001, error=6.461\n",
      ">epoch=21, lrate=0.001, error=0.051\n",
      ">epoch=21, lrate=0.001, error=2.676\n",
      ">epoch=21, lrate=0.001, error=2.834\n",
      ">epoch=21, lrate=0.001, error=2.834\n",
      ">epoch=21, lrate=0.001, error=6.009\n",
      ">epoch=22, lrate=0.001, error=0.043\n",
      ">epoch=22, lrate=0.001, error=2.566\n",
      ">epoch=22, lrate=0.001, error=2.681\n",
      ">epoch=22, lrate=0.001, error=2.683\n",
      ">epoch=22, lrate=0.001, error=5.607\n",
      ">epoch=23, lrate=0.001, error=0.036\n",
      ">epoch=23, lrate=0.001, error=2.465\n",
      ">epoch=23, lrate=0.001, error=2.544\n",
      ">epoch=23, lrate=0.001, error=2.552\n",
      ">epoch=23, lrate=0.001, error=5.251\n",
      ">epoch=24, lrate=0.001, error=0.030\n",
      ">epoch=24, lrate=0.001, error=2.372\n",
      ">epoch=24, lrate=0.001, error=2.424\n",
      ">epoch=24, lrate=0.001, error=2.440\n",
      ">epoch=24, lrate=0.001, error=4.935\n",
      ">epoch=25, lrate=0.001, error=0.025\n",
      ">epoch=25, lrate=0.001, error=2.286\n",
      ">epoch=25, lrate=0.001, error=2.318\n",
      ">epoch=25, lrate=0.001, error=2.345\n",
      ">epoch=25, lrate=0.001, error=4.655\n",
      ">epoch=26, lrate=0.001, error=0.021\n",
      ">epoch=26, lrate=0.001, error=2.207\n",
      ">epoch=26, lrate=0.001, error=2.224\n",
      ">epoch=26, lrate=0.001, error=2.264\n",
      ">epoch=26, lrate=0.001, error=4.406\n",
      ">epoch=27, lrate=0.001, error=0.017\n",
      ">epoch=27, lrate=0.001, error=2.133\n",
      ">epoch=27, lrate=0.001, error=2.141\n",
      ">epoch=27, lrate=0.001, error=2.196\n",
      ">epoch=27, lrate=0.001, error=4.186\n",
      ">epoch=28, lrate=0.001, error=0.014\n",
      ">epoch=28, lrate=0.001, error=2.066\n",
      ">epoch=28, lrate=0.001, error=2.068\n",
      ">epoch=28, lrate=0.001, error=2.138\n",
      ">epoch=28, lrate=0.001, error=3.990\n",
      ">epoch=29, lrate=0.001, error=0.011\n",
      ">epoch=29, lrate=0.001, error=2.003\n",
      ">epoch=29, lrate=0.001, error=2.003\n",
      ">epoch=29, lrate=0.001, error=2.090\n",
      ">epoch=29, lrate=0.001, error=3.816\n",
      ">epoch=30, lrate=0.001, error=0.009\n",
      ">epoch=30, lrate=0.001, error=1.946\n",
      ">epoch=30, lrate=0.001, error=1.946\n",
      ">epoch=30, lrate=0.001, error=2.050\n",
      ">epoch=30, lrate=0.001, error=3.662\n",
      ">epoch=31, lrate=0.001, error=0.007\n",
      ">epoch=31, lrate=0.001, error=1.892\n",
      ">epoch=31, lrate=0.001, error=1.896\n",
      ">epoch=31, lrate=0.001, error=2.017\n",
      ">epoch=31, lrate=0.001, error=3.525\n",
      ">epoch=32, lrate=0.001, error=0.006\n",
      ">epoch=32, lrate=0.001, error=1.843\n",
      ">epoch=32, lrate=0.001, error=1.852\n",
      ">epoch=32, lrate=0.001, error=1.991\n",
      ">epoch=32, lrate=0.001, error=3.404\n",
      ">epoch=33, lrate=0.001, error=0.004\n",
      ">epoch=33, lrate=0.001, error=1.797\n",
      ">epoch=33, lrate=0.001, error=1.813\n",
      ">epoch=33, lrate=0.001, error=1.970\n",
      ">epoch=33, lrate=0.001, error=3.296\n",
      ">epoch=34, lrate=0.001, error=0.003\n",
      ">epoch=34, lrate=0.001, error=1.754\n",
      ">epoch=34, lrate=0.001, error=1.779\n",
      ">epoch=34, lrate=0.001, error=1.953\n",
      ">epoch=34, lrate=0.001, error=3.200\n",
      ">epoch=35, lrate=0.001, error=0.002\n",
      ">epoch=35, lrate=0.001, error=1.714\n",
      ">epoch=35, lrate=0.001, error=1.748\n",
      ">epoch=35, lrate=0.001, error=1.941\n",
      ">epoch=35, lrate=0.001, error=3.115\n",
      ">epoch=36, lrate=0.001, error=0.002\n",
      ">epoch=36, lrate=0.001, error=1.678\n",
      ">epoch=36, lrate=0.001, error=1.722\n",
      ">epoch=36, lrate=0.001, error=1.932\n",
      ">epoch=36, lrate=0.001, error=3.040\n",
      ">epoch=37, lrate=0.001, error=0.001\n",
      ">epoch=37, lrate=0.001, error=1.643\n",
      ">epoch=37, lrate=0.001, error=1.698\n",
      ">epoch=37, lrate=0.001, error=1.925\n",
      ">epoch=37, lrate=0.001, error=2.973\n",
      ">epoch=38, lrate=0.001, error=0.001\n",
      ">epoch=38, lrate=0.001, error=1.612\n",
      ">epoch=38, lrate=0.001, error=1.678\n",
      ">epoch=38, lrate=0.001, error=1.921\n",
      ">epoch=38, lrate=0.001, error=2.914\n",
      ">epoch=39, lrate=0.001, error=0.000\n",
      ">epoch=39, lrate=0.001, error=1.582\n",
      ">epoch=39, lrate=0.001, error=1.660\n",
      ">epoch=39, lrate=0.001, error=1.920\n",
      ">epoch=39, lrate=0.001, error=2.862\n",
      ">epoch=40, lrate=0.001, error=0.000\n",
      ">epoch=40, lrate=0.001, error=1.554\n",
      ">epoch=40, lrate=0.001, error=1.644\n",
      ">epoch=40, lrate=0.001, error=1.920\n",
      ">epoch=40, lrate=0.001, error=2.815\n",
      ">epoch=41, lrate=0.001, error=0.000\n",
      ">epoch=41, lrate=0.001, error=1.529\n",
      ">epoch=41, lrate=0.001, error=1.630\n",
      ">epoch=41, lrate=0.001, error=1.921\n",
      ">epoch=41, lrate=0.001, error=2.773\n",
      ">epoch=42, lrate=0.001, error=0.000\n",
      ">epoch=42, lrate=0.001, error=1.505\n",
      ">epoch=42, lrate=0.001, error=1.618\n",
      ">epoch=42, lrate=0.001, error=1.924\n",
      ">epoch=42, lrate=0.001, error=2.737\n",
      ">epoch=43, lrate=0.001, error=0.000\n",
      ">epoch=43, lrate=0.001, error=1.482\n",
      ">epoch=43, lrate=0.001, error=1.607\n",
      ">epoch=43, lrate=0.001, error=1.928\n",
      ">epoch=43, lrate=0.001, error=2.704\n",
      ">epoch=44, lrate=0.001, error=0.000\n",
      ">epoch=44, lrate=0.001, error=1.462\n",
      ">epoch=44, lrate=0.001, error=1.598\n",
      ">epoch=44, lrate=0.001, error=1.932\n",
      ">epoch=44, lrate=0.001, error=2.675\n",
      ">epoch=45, lrate=0.001, error=0.000\n",
      ">epoch=45, lrate=0.001, error=1.442\n",
      ">epoch=45, lrate=0.001, error=1.590\n",
      ">epoch=45, lrate=0.001, error=1.937\n",
      ">epoch=45, lrate=0.001, error=2.650\n",
      ">epoch=46, lrate=0.001, error=0.000\n",
      ">epoch=46, lrate=0.001, error=1.424\n",
      ">epoch=46, lrate=0.001, error=1.582\n",
      ">epoch=46, lrate=0.001, error=1.943\n",
      ">epoch=46, lrate=0.001, error=2.627\n",
      ">epoch=47, lrate=0.001, error=0.000\n",
      ">epoch=47, lrate=0.001, error=1.407\n",
      ">epoch=47, lrate=0.001, error=1.576\n",
      ">epoch=47, lrate=0.001, error=1.949\n",
      ">epoch=47, lrate=0.001, error=2.607\n",
      ">epoch=48, lrate=0.001, error=0.001\n",
      ">epoch=48, lrate=0.001, error=1.391\n",
      ">epoch=48, lrate=0.001, error=1.571\n",
      ">epoch=48, lrate=0.001, error=1.955\n",
      ">epoch=48, lrate=0.001, error=2.589\n",
      ">epoch=49, lrate=0.001, error=0.001\n",
      ">epoch=49, lrate=0.001, error=1.376\n",
      ">epoch=49, lrate=0.001, error=1.566\n",
      ">epoch=49, lrate=0.001, error=1.962\n",
      ">epoch=49, lrate=0.001, error=2.573\n",
      "[0.22998234937311363, 0.8017220304137576]\n"
     ]
    }
   ],
   "source": [
    "# Calculate coefficients\n",
    "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
    "l_rate = 0.001\n",
    "n_epoch = 50\n",
    "coef = coefficients_sgd(dataset, l_rate, n_epoch)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
